{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for file in glob.glob('fhir/general/*'):\n",
    "    raw_data.append(pd.read_json(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dataPipeTuples(raw_data):\n",
    "    training_data = {}\n",
    "    for patient in raw_data:\n",
    "        id = patient['entry'][0]['resource']['id']\n",
    "        training_data[id] = {}\n",
    "        #total number of times patient is inpatient for chf\n",
    "        training_data[id]['total_chf'] = 0\n",
    "        #first time of discharge for chf and second time admitted for chf\n",
    "        training_data[id]['chf_dates'] = ()\n",
    "        \n",
    "        for entry in patient['entry']:\n",
    "            resource_type = entry['resource']['resourceType']\n",
    "            if resource_type == \"Encounter\":\n",
    "                class_code = entry['resource']['class']['code']\n",
    "                if class_code == \"IMP\" or class_code == \"EMER\":\n",
    "                    try:\n",
    "                        reason_code = entry['resource']['reasonCode'][0]['coding'][0]['code']\n",
    "                    except:\n",
    "                        continue\n",
    "                    start_date = entry['resource']['period']['start'][0:10]\n",
    "                    if (training_data[id]['total_chf'] == 1):\n",
    "                        if (pd.date_range(training_data[id]['chf_dates'][0], start_date).shape[0] > 29):\n",
    "                            if reason_code == \"88805009\":\n",
    "                                training_data[id]['total_chf'] += 1\n",
    "                    else:\n",
    "                        if reason_code == \"88805009\":\n",
    "                            training_data[id]['total_chf'] += 1\n",
    "                            \n",
    "                if (training_data[id]['total_chf'] == 1):\n",
    "                    training_data[id]['chf_dates'] = (entry['resource']['period']['end'][0:10],)\n",
    "                elif (training_data[id]['total_chf'] == 2):\n",
    "                    training_data[id]['chf_dates'] = (training_data[id]['chf_dates'][0], start_date)\n",
    "        if (training_data[id]['total_chf'] == 0):\n",
    "            del training_data[id]\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPipeMatrix(raw_data, tuple_list):\n",
    "    training_data = {}\n",
    "    for patient in raw_data:\n",
    "        id = patient['entry'][0]['resource']['id']\n",
    "        if id in tuple_list:\n",
    "            training_data[id] = defaultdict(Counter)\n",
    "            check_date = tuple_list[id]['chf_dates'][0]\n",
    "            for entry in patient['entry']:\n",
    "                resource_type = entry['resource']['resourceType']\n",
    "\n",
    "                if resource_type == \"Encounter\":\n",
    "                    start_date = entry['resource']['period']['start'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        try:\n",
    "                            reason_code = entry['resource']['reasonCode'][0]['coding'][0]['code']\n",
    "                        except:\n",
    "                            reason_code = entry['resource']['type'][0]['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Observation\":\n",
    "                    start_date = entry['resource']['effectiveDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1 \n",
    "                elif resource_type == \"Procedure\":\n",
    "                    start_date = entry['resource']['performedPeriod']['start'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Condition\":\n",
    "                    start_date = entry['resource']['onsetDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Immunization\":\n",
    "                    start_date = entry['resource']['occurrenceDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['vaccineCode']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"MedicationRequest\":\n",
    "                    start_date = entry['resource']['authoredOn'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['medicationCodeableConcept']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMonth(dt):\n",
    "    month = int(dt[5:])\n",
    "    year = int(dt[0:4])\n",
    "    if month == 12:\n",
    "        return str(year+1)+\"-01\"\n",
    "    else:\n",
    "        date = str(month+1).zfill(2)\n",
    "        return dt[0:5]+date\n",
    "def addYear(dt, num):\n",
    "    year = int(dt[0:4])\n",
    "    date = str(year+num)\n",
    "    return date+dt[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPipeDataFrames(raw_data):\n",
    "    frames = []\n",
    "    tuples = dataPipeTuples(raw_data)\n",
    "    data = dataPipeMatrix(raw_data, tuples)\n",
    "    for id in data:\n",
    "        df = pd.DataFrame.from_dict(data[id], orient=\"index\")\n",
    "        df = df.reset_index().rename(columns={'index':'Month'}).sort_values(by='Month', ascending=False)\n",
    "        two_year_range = np.arange(np.datetime64(addYear(tuples[id]['chf_dates'][0][0:7], -2)), np.datetime64(addMonth(tuples[id]['chf_dates'][0][0:7]))).astype(str).tolist()\n",
    "        df = df.set_index('Month').reindex(two_year_range).sort_values(by='Month', ascending=False).fillna(0)\n",
    "        frames.append(df)\n",
    "    all_columns = []\n",
    "    for frame in frames:\n",
    "        all_columns.extend(x for x in frame.columns.tolist() if not x in all_columns)\n",
    "    final_frames = []\n",
    "    for df in frames:\n",
    "        cols = df.columns.tolist()\n",
    "        cols.extend(x for x in all_columns if not x in cols)\n",
    "        df = df.reindex(columns=sorted(cols, reverse=True), fill_value=0)\n",
    "        final_frames.append(df)\n",
    "    return (final_frames, tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, tuples = dataPipeDataFrames(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(tuples, orient=\"index\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 327)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data \n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame.from_dict(tuples, orient=\"index\")\n",
    "labels = labels.drop(columns=['chf_dates'])\n",
    "labels = labels.mask(labels == 1, 0)\n",
    "labels = labels.mask(labels > 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "for df in frames:\n",
    "    ff.append(df.values)\n",
    "x = torch.Tensor(ff)\n",
    "x = x.view(-1,1,25,327)\n",
    "y = torch.Tensor(labels.values).squeeze().type(torch.LongTensor)\n",
    "train = torch.utils.data.TensorDataset(x, y)\n",
    "train_size = int(0.8 * len(train))\n",
    "test_size = len(train) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 1, 25, 327])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            #print(y_batch.shape)\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(epoch)\n",
    "            print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch train and test sets\n",
    "#train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "#test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(4, 79))\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(4, 79))\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=(4, 79))\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/53 (0%)]\tLoss: 0.695359\t Accuracy:50.000%\n",
      "Epoch : 0 [2/53 (4%)]\tLoss: 0.739040\t Accuracy:25.000%\n",
      "Epoch : 0 [4/53 (7%)]\tLoss: 0.597191\t Accuracy:50.000%\n",
      "Epoch : 0 [6/53 (11%)]\tLoss: 0.830404\t Accuracy:37.500%\n",
      "Epoch : 0 [8/53 (15%)]\tLoss: 0.441549\t Accuracy:50.000%\n",
      "Epoch : 0 [10/53 (19%)]\tLoss: 1.048050\t Accuracy:50.000%\n",
      "Epoch : 0 [12/53 (22%)]\tLoss: 0.467941\t Accuracy:57.143%\n",
      "Epoch : 0 [14/53 (26%)]\tLoss: 0.872179\t Accuracy:56.250%\n",
      "Epoch : 0 [16/53 (30%)]\tLoss: 0.512904\t Accuracy:61.111%\n",
      "Epoch : 0 [18/53 (33%)]\tLoss: 0.641593\t Accuracy:60.000%\n",
      "Epoch : 0 [20/53 (37%)]\tLoss: 0.493430\t Accuracy:63.636%\n",
      "Epoch : 0 [22/53 (41%)]\tLoss: 0.266922\t Accuracy:66.667%\n",
      "Epoch : 0 [24/53 (44%)]\tLoss: 0.222283\t Accuracy:69.231%\n",
      "Epoch : 0 [26/53 (48%)]\tLoss: 0.009493\t Accuracy:71.429%\n",
      "Epoch : 0 [28/53 (52%)]\tLoss: 0.002126\t Accuracy:73.333%\n",
      "Epoch : 0 [30/53 (56%)]\tLoss: 4.407306\t Accuracy:71.875%\n",
      "Epoch : 0 [32/53 (59%)]\tLoss: 0.008687\t Accuracy:73.529%\n",
      "Epoch : 0 [34/53 (63%)]\tLoss: 2.483191\t Accuracy:72.222%\n",
      "Epoch : 0 [36/53 (67%)]\tLoss: 1.874968\t Accuracy:71.053%\n",
      "Epoch : 0 [38/53 (70%)]\tLoss: 0.329970\t Accuracy:72.500%\n",
      "Epoch : 0 [40/53 (74%)]\tLoss: 0.461655\t Accuracy:73.810%\n",
      "Epoch : 0 [42/53 (78%)]\tLoss: 0.488005\t Accuracy:75.000%\n",
      "Epoch : 0 [44/53 (81%)]\tLoss: 0.535898\t Accuracy:76.087%\n",
      "Epoch : 0 [46/53 (85%)]\tLoss: 0.596255\t Accuracy:77.083%\n",
      "Epoch : 0 [48/53 (89%)]\tLoss: 0.625874\t Accuracy:78.000%\n",
      "Epoch : 0 [50/53 (93%)]\tLoss: 0.582875\t Accuracy:78.846%\n",
      "Epoch : 0 [26/53 (96%)]\tLoss: 0.560088\t Accuracy:77.778%\n",
      "Epoch : 1 [0/53 (0%)]\tLoss: 0.736861\t Accuracy:50.000%\n",
      "Epoch : 1 [2/53 (4%)]\tLoss: 0.757113\t Accuracy:50.000%\n",
      "Epoch : 1 [4/53 (7%)]\tLoss: 0.450218\t Accuracy:66.667%\n",
      "Epoch : 1 [6/53 (11%)]\tLoss: 1.048689\t Accuracy:50.000%\n",
      "Epoch : 1 [8/53 (15%)]\tLoss: 0.439761\t Accuracy:60.000%\n",
      "Epoch : 1 [10/53 (19%)]\tLoss: 0.764097\t Accuracy:58.333%\n",
      "Epoch : 1 [12/53 (22%)]\tLoss: 0.474201\t Accuracy:64.286%\n",
      "Epoch : 1 [14/53 (26%)]\tLoss: 0.750516\t Accuracy:62.500%\n",
      "Epoch : 1 [16/53 (30%)]\tLoss: 0.467926\t Accuracy:66.667%\n",
      "Epoch : 1 [18/53 (33%)]\tLoss: 0.648159\t Accuracy:65.000%\n",
      "Epoch : 1 [20/53 (37%)]\tLoss: 0.419651\t Accuracy:68.182%\n",
      "Epoch : 1 [22/53 (41%)]\tLoss: 0.309641\t Accuracy:70.833%\n",
      "Epoch : 1 [24/53 (44%)]\tLoss: 0.303382\t Accuracy:73.077%\n",
      "Epoch : 1 [26/53 (48%)]\tLoss: 0.274584\t Accuracy:75.000%\n",
      "Epoch : 1 [28/53 (52%)]\tLoss: 0.158520\t Accuracy:76.667%\n",
      "Epoch : 1 [30/53 (56%)]\tLoss: 1.293031\t Accuracy:75.000%\n",
      "Epoch : 1 [32/53 (59%)]\tLoss: 0.041789\t Accuracy:76.471%\n",
      "Epoch : 1 [34/53 (63%)]\tLoss: 1.752751\t Accuracy:75.000%\n",
      "Epoch : 1 [36/53 (67%)]\tLoss: 1.195289\t Accuracy:73.684%\n",
      "Epoch : 1 [38/53 (70%)]\tLoss: 0.063483\t Accuracy:75.000%\n",
      "Epoch : 1 [40/53 (74%)]\tLoss: 0.160087\t Accuracy:76.190%\n",
      "Epoch : 1 [42/53 (78%)]\tLoss: 0.178003\t Accuracy:77.273%\n",
      "Epoch : 1 [44/53 (81%)]\tLoss: 0.131892\t Accuracy:78.261%\n",
      "Epoch : 1 [46/53 (85%)]\tLoss: 0.116824\t Accuracy:79.167%\n",
      "Epoch : 1 [48/53 (89%)]\tLoss: 0.123304\t Accuracy:80.000%\n",
      "Epoch : 1 [50/53 (93%)]\tLoss: 0.154865\t Accuracy:80.769%\n",
      "Epoch : 1 [26/53 (96%)]\tLoss: 0.050742\t Accuracy:79.630%\n",
      "Epoch : 2 [0/53 (0%)]\tLoss: 1.398466\t Accuracy:50.000%\n",
      "Epoch : 2 [2/53 (4%)]\tLoss: 1.453843\t Accuracy:50.000%\n",
      "Epoch : 2 [4/53 (7%)]\tLoss: 0.108550\t Accuracy:66.667%\n",
      "Epoch : 2 [6/53 (11%)]\tLoss: 1.711661\t Accuracy:50.000%\n",
      "Epoch : 2 [8/53 (15%)]\tLoss: 0.221540\t Accuracy:60.000%\n",
      "Epoch : 2 [10/53 (19%)]\tLoss: 0.772235\t Accuracy:58.333%\n",
      "Epoch : 2 [12/53 (22%)]\tLoss: 0.421841\t Accuracy:64.286%\n",
      "Epoch : 2 [14/53 (26%)]\tLoss: 0.715456\t Accuracy:62.500%\n",
      "Epoch : 2 [16/53 (30%)]\tLoss: 0.537217\t Accuracy:66.667%\n",
      "Epoch : 2 [18/53 (33%)]\tLoss: 0.702453\t Accuracy:65.000%\n",
      "Epoch : 2 [20/53 (37%)]\tLoss: 0.591096\t Accuracy:68.182%\n",
      "Epoch : 2 [22/53 (41%)]\tLoss: 0.573412\t Accuracy:70.833%\n",
      "Epoch : 2 [24/53 (44%)]\tLoss: 0.539920\t Accuracy:73.077%\n",
      "Epoch : 2 [26/53 (48%)]\tLoss: 0.484326\t Accuracy:75.000%\n",
      "Epoch : 2 [28/53 (52%)]\tLoss: 0.517525\t Accuracy:76.667%\n",
      "Epoch : 2 [30/53 (56%)]\tLoss: 0.751841\t Accuracy:75.000%\n",
      "Epoch : 2 [32/53 (59%)]\tLoss: 0.514079\t Accuracy:76.471%\n",
      "Epoch : 2 [34/53 (63%)]\tLoss: 0.712848\t Accuracy:75.000%\n",
      "Epoch : 2 [36/53 (67%)]\tLoss: 0.688470\t Accuracy:73.684%\n",
      "Epoch : 2 [38/53 (70%)]\tLoss: 0.481361\t Accuracy:75.000%\n",
      "Epoch : 2 [40/53 (74%)]\tLoss: 0.481612\t Accuracy:76.190%\n",
      "Epoch : 2 [42/53 (78%)]\tLoss: 0.420256\t Accuracy:77.273%\n",
      "Epoch : 2 [44/53 (81%)]\tLoss: 0.278355\t Accuracy:78.261%\n",
      "Epoch : 2 [46/53 (85%)]\tLoss: 0.211009\t Accuracy:79.167%\n",
      "Epoch : 2 [48/53 (89%)]\tLoss: 0.197514\t Accuracy:80.000%\n",
      "Epoch : 2 [50/53 (93%)]\tLoss: 0.082289\t Accuracy:80.769%\n",
      "Epoch : 2 [26/53 (96%)]\tLoss: 0.033325\t Accuracy:79.630%\n",
      "Epoch : 3 [0/53 (0%)]\tLoss: 1.886742\t Accuracy:50.000%\n",
      "Epoch : 3 [2/53 (4%)]\tLoss: 2.152812\t Accuracy:50.000%\n",
      "Epoch : 3 [4/53 (7%)]\tLoss: 0.042140\t Accuracy:66.667%\n",
      "Epoch : 3 [6/53 (11%)]\tLoss: 2.193021\t Accuracy:50.000%\n",
      "Epoch : 3 [8/53 (15%)]\tLoss: 0.156834\t Accuracy:60.000%\n",
      "Epoch : 3 [10/53 (19%)]\tLoss: 1.018495\t Accuracy:58.333%\n",
      "Epoch : 3 [12/53 (22%)]\tLoss: 0.332751\t Accuracy:64.286%\n",
      "Epoch : 3 [14/53 (26%)]\tLoss: 0.682448\t Accuracy:62.500%\n",
      "Epoch : 3 [16/53 (30%)]\tLoss: 0.470293\t Accuracy:66.667%\n",
      "Epoch : 3 [18/53 (33%)]\tLoss: 0.717996\t Accuracy:65.000%\n",
      "Epoch : 3 [20/53 (37%)]\tLoss: 0.537163\t Accuracy:68.182%\n",
      "Epoch : 3 [22/53 (41%)]\tLoss: 0.523489\t Accuracy:70.833%\n",
      "Epoch : 3 [24/53 (44%)]\tLoss: 0.541450\t Accuracy:73.077%\n",
      "Epoch : 3 [26/53 (48%)]\tLoss: 0.553186\t Accuracy:75.000%\n",
      "Epoch : 3 [28/53 (52%)]\tLoss: 0.564361\t Accuracy:76.667%\n",
      "Epoch : 3 [30/53 (56%)]\tLoss: 0.704945\t Accuracy:75.000%\n",
      "Epoch : 3 [32/53 (59%)]\tLoss: 0.589075\t Accuracy:76.471%\n",
      "Epoch : 3 [34/53 (63%)]\tLoss: 0.708550\t Accuracy:75.000%\n",
      "Epoch : 3 [36/53 (67%)]\tLoss: 0.714348\t Accuracy:73.684%\n",
      "Epoch : 3 [38/53 (70%)]\tLoss: 0.600564\t Accuracy:75.000%\n",
      "Epoch : 3 [40/53 (74%)]\tLoss: 0.579803\t Accuracy:76.190%\n",
      "Epoch : 3 [42/53 (78%)]\tLoss: 0.560502\t Accuracy:77.273%\n",
      "Epoch : 3 [44/53 (81%)]\tLoss: 0.574222\t Accuracy:78.261%\n",
      "Epoch : 3 [46/53 (85%)]\tLoss: 0.530587\t Accuracy:79.167%\n",
      "Epoch : 3 [48/53 (89%)]\tLoss: 0.543428\t Accuracy:80.000%\n",
      "Epoch : 3 [50/53 (93%)]\tLoss: 0.556068\t Accuracy:80.769%\n",
      "Epoch : 3 [26/53 (96%)]\tLoss: 0.549250\t Accuracy:79.630%\n",
      "Epoch : 4 [0/53 (0%)]\tLoss: 0.682487\t Accuracy:50.000%\n",
      "Epoch : 4 [2/53 (4%)]\tLoss: 0.642772\t Accuracy:50.000%\n",
      "Epoch : 4 [4/53 (7%)]\tLoss: 0.489013\t Accuracy:66.667%\n",
      "Epoch : 4 [6/53 (11%)]\tLoss: 0.916280\t Accuracy:50.000%\n",
      "Epoch : 4 [8/53 (15%)]\tLoss: 0.461714\t Accuracy:60.000%\n",
      "Epoch : 4 [10/53 (19%)]\tLoss: 0.622213\t Accuracy:58.333%\n",
      "Epoch : 4 [12/53 (22%)]\tLoss: 0.394934\t Accuracy:64.286%\n",
      "Epoch : 4 [14/53 (26%)]\tLoss: 0.666191\t Accuracy:62.500%\n",
      "Epoch : 4 [16/53 (30%)]\tLoss: 0.365992\t Accuracy:66.667%\n",
      "Epoch : 4 [18/53 (33%)]\tLoss: 0.673086\t Accuracy:65.000%\n",
      "Epoch : 4 [20/53 (37%)]\tLoss: 0.288154\t Accuracy:68.182%\n",
      "Epoch : 4 [22/53 (41%)]\tLoss: 0.155197\t Accuracy:70.833%\n",
      "Epoch : 4 [24/53 (44%)]\tLoss: 0.114364\t Accuracy:73.077%\n",
      "Epoch : 4 [26/53 (48%)]\tLoss: 0.007496\t Accuracy:75.000%\n",
      "Epoch : 4 [28/53 (52%)]\tLoss: 0.029658\t Accuracy:76.667%\n",
      "Epoch : 4 [30/53 (56%)]\tLoss: 2.407815\t Accuracy:75.000%\n",
      "Epoch : 4 [32/53 (59%)]\tLoss: 0.066932\t Accuracy:76.471%\n",
      "Epoch : 4 [34/53 (63%)]\tLoss: 0.912153\t Accuracy:75.000%\n",
      "Epoch : 4 [36/53 (67%)]\tLoss: 1.302922\t Accuracy:73.684%\n",
      "Epoch : 4 [38/53 (70%)]\tLoss: 0.256638\t Accuracy:75.000%\n",
      "Epoch : 4 [40/53 (74%)]\tLoss: 0.213543\t Accuracy:76.190%\n",
      "Epoch : 4 [42/53 (78%)]\tLoss: 0.323653\t Accuracy:77.273%\n",
      "Epoch : 4 [44/53 (81%)]\tLoss: 0.297360\t Accuracy:78.261%\n",
      "Epoch : 4 [46/53 (85%)]\tLoss: 0.265138\t Accuracy:79.167%\n",
      "Epoch : 4 [48/53 (89%)]\tLoss: 0.291390\t Accuracy:80.000%\n",
      "Epoch : 4 [50/53 (93%)]\tLoss: 0.380379\t Accuracy:80.769%\n",
      "Epoch : 4 [26/53 (96%)]\tLoss: 0.170543\t Accuracy:79.630%\n"
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.857% \n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
