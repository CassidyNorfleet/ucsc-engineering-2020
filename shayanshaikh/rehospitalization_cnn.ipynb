{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for file in glob.glob('fhir/general/*'):\n",
    "    raw_data.append(pd.read_json(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dataPipeTuples(raw_data):\n",
    "    training_data = {}\n",
    "    for patient in raw_data:\n",
    "        id = patient['entry'][0]['resource']['id']\n",
    "        training_data[id] = {}\n",
    "        #total number of times patient is inpatient for chf\n",
    "        training_data[id]['total_chf'] = 0\n",
    "        #first time of discharge for chf and second time admitted for chf\n",
    "        training_data[id]['chf_dates'] = ()\n",
    "        \n",
    "        for entry in patient['entry']:\n",
    "            resource_type = entry['resource']['resourceType']\n",
    "            if resource_type == \"Encounter\":\n",
    "                class_code = entry['resource']['class']['code']\n",
    "                if class_code == \"IMP\" or class_code == \"EMER\":\n",
    "                    try:\n",
    "                        reason_code = entry['resource']['reasonCode'][0]['coding'][0]['code']\n",
    "                    except:\n",
    "                        continue\n",
    "                    start_date = entry['resource']['period']['start'][0:10]\n",
    "                    if (training_data[id]['total_chf'] == 1):\n",
    "                        if (pd.date_range(training_data[id]['chf_dates'][0], start_date).shape[0] > 29):\n",
    "                            if reason_code == \"88805009\":\n",
    "                                training_data[id]['total_chf'] += 1\n",
    "                    else:\n",
    "                        if reason_code == \"88805009\":\n",
    "                            training_data[id]['total_chf'] += 1\n",
    "                            \n",
    "                if (training_data[id]['total_chf'] == 1):\n",
    "                    training_data[id]['chf_dates'] = (entry['resource']['period']['end'][0:10],)\n",
    "                elif (training_data[id]['total_chf'] == 2):\n",
    "                    training_data[id]['chf_dates'] = (training_data[id]['chf_dates'][0], start_date)\n",
    "        if (training_data[id]['total_chf'] == 0):\n",
    "            del training_data[id]\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPipeMatrix(raw_data, tuple_list):\n",
    "    training_data = {}\n",
    "    for patient in raw_data:\n",
    "        id = patient['entry'][0]['resource']['id']\n",
    "        if id in tuple_list:\n",
    "            training_data[id] = defaultdict(Counter)\n",
    "            check_date = tuple_list[id]['chf_dates'][0]\n",
    "            for entry in patient['entry']:\n",
    "                resource_type = entry['resource']['resourceType']\n",
    "\n",
    "                if resource_type == \"Encounter\":\n",
    "                    start_date = entry['resource']['period']['start'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        try:\n",
    "                            reason_code = entry['resource']['reasonCode'][0]['coding'][0]['code']\n",
    "                        except:\n",
    "                            reason_code = entry['resource']['type'][0]['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Observation\":\n",
    "                    start_date = entry['resource']['effectiveDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1 \n",
    "                elif resource_type == \"Procedure\":\n",
    "                    start_date = entry['resource']['performedPeriod']['start'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Condition\":\n",
    "                    start_date = entry['resource']['onsetDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['code']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"Immunization\":\n",
    "                    start_date = entry['resource']['occurrenceDateTime'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['vaccineCode']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "                elif resource_type == \"MedicationRequest\":\n",
    "                    start_date = entry['resource']['authoredOn'][0:7]\n",
    "                    if pd.date_range(start_date, check_date).shape[0] != 0:\n",
    "                        reason_code = entry['resource']['medicationCodeableConcept']['coding'][0]['code']\n",
    "                        training_data[id][start_date][reason_code] = 1\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMonth(dt):\n",
    "    month = int(dt[5:])\n",
    "    year = int(dt[0:4])\n",
    "    if month == 12:\n",
    "        return str(year+1)+\"-01\"\n",
    "    else:\n",
    "        date = str(month+1).zfill(2)\n",
    "        return dt[0:5]+date\n",
    "def addYear(dt, num):\n",
    "    year = int(dt[0:4])\n",
    "    date = str(year+num)\n",
    "    return date+dt[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPipeDataFrames(raw_data):\n",
    "    frames = []\n",
    "    tuples = dataPipeTuples(raw_data)\n",
    "    data = dataPipeMatrix(raw_data, tuples)\n",
    "    for id in data:\n",
    "        df = pd.DataFrame.from_dict(data[id], orient=\"index\")\n",
    "        df = df.reset_index().rename(columns={'index':'Month'}).sort_values(by='Month', ascending=True)\n",
    "        two_year_range = np.arange(np.datetime64(addYear(tuples[id]['chf_dates'][0][0:7], -2)), np.datetime64(addMonth(tuples[id]['chf_dates'][0][0:7]))).astype(str).tolist()\n",
    "        df = df.set_index('Month').reindex(two_year_range).sort_values(by='Month', ascending=False).fillna(0)\n",
    "        frames.append(df)\n",
    "    all_columns = []\n",
    "    for frame in frames:\n",
    "        all_columns.extend(x for x in frame.columns.tolist() if not x in all_columns)\n",
    "    final_frames = []\n",
    "    for df in frames:\n",
    "        cols = df.columns.tolist()\n",
    "        cols.extend(x for x in all_columns if not x in cols)\n",
    "        df = df.reindex(columns=sorted(cols, reverse=True), fill_value=0)\n",
    "        final_frames.append(df)\n",
    "    return (final_frames, tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, tuples = dataPipeDataFrames(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(tuples, orient=\"index\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 327)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data \n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame.from_dict(tuples, orient=\"index\")\n",
    "labels = labels.drop(columns=['chf_dates'])\n",
    "labels = labels.mask(labels == 1, 0)\n",
    "labels = labels.mask(labels > 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "for df in frames:\n",
    "    ff.append(df.values)\n",
    "x = torch.Tensor(ff)\n",
    "x = x.view(-1,1,25,327)\n",
    "y = torch.Tensor(labels.values).squeeze().type(torch.LongTensor)\n",
    "train = torch.utils.data.TensorDataset(x, y)\n",
    "train_size = int(0.8 * len(train))\n",
    "test_size = len(train) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 1, 25, 327])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            #print(y_batch.shape)\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(epoch)\n",
    "            print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch train and test sets\n",
    "#train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "#test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(4, 79), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(4, 79))\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(4, 79))\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=(4, 79))\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    " \n",
    "cnn = CNN()\n",
    "print(cnn)\n",
    "\n",
    "it = iter(train_loader)\n",
    "X_batch, y_batch = next(it)\n",
    "print(cnn.forward(X_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/53 (0%)]\tLoss: 0.693527\t Accuracy:50.000%\n",
      "Epoch : 0 [2/53 (4%)]\tLoss: 0.348073\t Accuracy:75.000%\n",
      "Epoch : 0 [4/53 (7%)]\tLoss: 1.711577\t Accuracy:66.667%\n",
      "Epoch : 0 [6/53 (11%)]\tLoss: 0.052099\t Accuracy:75.000%\n",
      "Epoch : 0 [8/53 (15%)]\tLoss: 0.028860\t Accuracy:80.000%\n",
      "Epoch : 0 [10/53 (19%)]\tLoss: 0.037059\t Accuracy:83.333%\n",
      "Epoch : 0 [12/53 (22%)]\tLoss: 2.595680\t Accuracy:78.571%\n",
      "Epoch : 0 [14/53 (26%)]\tLoss: 0.020654\t Accuracy:81.250%\n",
      "Epoch : 0 [16/53 (30%)]\tLoss: 0.785532\t Accuracy:77.778%\n",
      "Epoch : 0 [18/53 (33%)]\tLoss: 0.525551\t Accuracy:80.000%\n",
      "Epoch : 0 [20/53 (37%)]\tLoss: 0.730705\t Accuracy:77.273%\n",
      "Epoch : 0 [22/53 (41%)]\tLoss: 0.714338\t Accuracy:75.000%\n",
      "Epoch : 0 [24/53 (44%)]\tLoss: 0.642936\t Accuracy:76.923%\n",
      "Epoch : 0 [26/53 (48%)]\tLoss: 0.657607\t Accuracy:78.571%\n",
      "Epoch : 0 [28/53 (52%)]\tLoss: 0.693731\t Accuracy:76.667%\n",
      "Epoch : 0 [30/53 (56%)]\tLoss: 0.663055\t Accuracy:75.000%\n",
      "Epoch : 0 [32/53 (59%)]\tLoss: 0.694845\t Accuracy:73.529%\n",
      "Epoch : 0 [34/53 (63%)]\tLoss: 0.590110\t Accuracy:75.000%\n",
      "Epoch : 0 [36/53 (67%)]\tLoss: 0.535418\t Accuracy:76.316%\n",
      "Epoch : 0 [38/53 (70%)]\tLoss: 0.364471\t Accuracy:77.500%\n",
      "Epoch : 0 [40/53 (74%)]\tLoss: 0.421444\t Accuracy:78.571%\n",
      "Epoch : 0 [42/53 (78%)]\tLoss: 0.185043\t Accuracy:79.545%\n",
      "Epoch : 0 [44/53 (81%)]\tLoss: 1.190285\t Accuracy:78.261%\n",
      "Epoch : 0 [46/53 (85%)]\tLoss: 0.097472\t Accuracy:79.167%\n",
      "Epoch : 0 [48/53 (89%)]\tLoss: 1.614660\t Accuracy:78.000%\n",
      "Epoch : 0 [50/53 (93%)]\tLoss: 0.100959\t Accuracy:78.846%\n",
      "Epoch : 0 [26/53 (96%)]\tLoss: 2.886857\t Accuracy:75.926%\n",
      "Epoch : 1 [0/53 (0%)]\tLoss: 0.136439\t Accuracy:100.000%\n",
      "Epoch : 1 [2/53 (4%)]\tLoss: 0.142821\t Accuracy:100.000%\n",
      "Epoch : 1 [4/53 (7%)]\tLoss: 1.027040\t Accuracy:83.333%\n",
      "Epoch : 1 [6/53 (11%)]\tLoss: 0.362017\t Accuracy:87.500%\n",
      "Epoch : 1 [8/53 (15%)]\tLoss: 0.353502\t Accuracy:90.000%\n",
      "Epoch : 1 [10/53 (19%)]\tLoss: 0.441377\t Accuracy:91.667%\n",
      "Epoch : 1 [12/53 (22%)]\tLoss: 0.739482\t Accuracy:85.714%\n",
      "Epoch : 1 [14/53 (26%)]\tLoss: 0.377971\t Accuracy:87.500%\n",
      "Epoch : 1 [16/53 (30%)]\tLoss: 0.776775\t Accuracy:83.333%\n",
      "Epoch : 1 [18/53 (33%)]\tLoss: 0.396764\t Accuracy:85.000%\n",
      "Epoch : 1 [20/53 (37%)]\tLoss: 0.714157\t Accuracy:81.818%\n",
      "Epoch : 1 [22/53 (41%)]\tLoss: 0.666186\t Accuracy:79.167%\n",
      "Epoch : 1 [24/53 (44%)]\tLoss: 0.342399\t Accuracy:80.769%\n",
      "Epoch : 1 [26/53 (48%)]\tLoss: 0.338128\t Accuracy:82.143%\n",
      "Epoch : 1 [28/53 (52%)]\tLoss: 0.832839\t Accuracy:80.000%\n",
      "Epoch : 1 [30/53 (56%)]\tLoss: 0.752961\t Accuracy:78.125%\n",
      "Epoch : 1 [32/53 (59%)]\tLoss: 0.737784\t Accuracy:76.471%\n",
      "Epoch : 1 [34/53 (63%)]\tLoss: 0.395838\t Accuracy:77.778%\n",
      "Epoch : 1 [36/53 (67%)]\tLoss: 0.329974\t Accuracy:78.947%\n",
      "Epoch : 1 [38/53 (70%)]\tLoss: 0.312264\t Accuracy:80.000%\n",
      "Epoch : 1 [40/53 (74%)]\tLoss: 0.313728\t Accuracy:80.952%\n",
      "Epoch : 1 [42/53 (78%)]\tLoss: 0.175561\t Accuracy:81.818%\n",
      "Epoch : 1 [44/53 (81%)]\tLoss: 0.870129\t Accuracy:80.435%\n",
      "Epoch : 1 [46/53 (85%)]\tLoss: 0.197501\t Accuracy:81.250%\n",
      "Epoch : 1 [48/53 (89%)]\tLoss: 0.995351\t Accuracy:80.000%\n",
      "Epoch : 1 [50/53 (93%)]\tLoss: 0.138544\t Accuracy:80.769%\n",
      "Epoch : 1 [26/53 (96%)]\tLoss: 2.793796\t Accuracy:77.778%\n",
      "Epoch : 2 [0/53 (0%)]\tLoss: 0.157545\t Accuracy:100.000%\n",
      "Epoch : 2 [2/53 (4%)]\tLoss: 0.185781\t Accuracy:100.000%\n",
      "Epoch : 2 [4/53 (7%)]\tLoss: 1.001921\t Accuracy:83.333%\n",
      "Epoch : 2 [6/53 (11%)]\tLoss: 0.364096\t Accuracy:87.500%\n",
      "Epoch : 2 [8/53 (15%)]\tLoss: 0.330504\t Accuracy:90.000%\n",
      "Epoch : 2 [10/53 (19%)]\tLoss: 0.300835\t Accuracy:91.667%\n",
      "Epoch : 2 [12/53 (22%)]\tLoss: 0.648430\t Accuracy:85.714%\n",
      "Epoch : 2 [14/53 (26%)]\tLoss: 0.336718\t Accuracy:87.500%\n",
      "Epoch : 2 [16/53 (30%)]\tLoss: 0.794717\t Accuracy:83.333%\n",
      "Epoch : 2 [18/53 (33%)]\tLoss: 0.351931\t Accuracy:85.000%\n",
      "Epoch : 2 [20/53 (37%)]\tLoss: 0.861570\t Accuracy:81.818%\n",
      "Epoch : 2 [22/53 (41%)]\tLoss: 0.661156\t Accuracy:79.167%\n",
      "Epoch : 2 [24/53 (44%)]\tLoss: 0.396191\t Accuracy:80.769%\n",
      "Epoch : 2 [26/53 (48%)]\tLoss: 0.306331\t Accuracy:82.143%\n",
      "Epoch : 2 [28/53 (52%)]\tLoss: 0.793149\t Accuracy:80.000%\n",
      "Epoch : 2 [30/53 (56%)]\tLoss: 0.920473\t Accuracy:78.125%\n",
      "Epoch : 2 [32/53 (59%)]\tLoss: 0.670377\t Accuracy:76.471%\n",
      "Epoch : 2 [34/53 (63%)]\tLoss: 0.372822\t Accuracy:77.778%\n",
      "Epoch : 2 [36/53 (67%)]\tLoss: 0.321998\t Accuracy:78.947%\n",
      "Epoch : 2 [38/53 (70%)]\tLoss: 0.295841\t Accuracy:80.000%\n",
      "Epoch : 2 [40/53 (74%)]\tLoss: 0.308684\t Accuracy:80.952%\n",
      "Epoch : 2 [42/53 (78%)]\tLoss: 0.181784\t Accuracy:81.818%\n",
      "Epoch : 2 [44/53 (81%)]\tLoss: 1.183010\t Accuracy:80.435%\n",
      "Epoch : 2 [46/53 (85%)]\tLoss: 0.207732\t Accuracy:81.250%\n",
      "Epoch : 2 [48/53 (89%)]\tLoss: 1.023242\t Accuracy:80.000%\n",
      "Epoch : 2 [50/53 (93%)]\tLoss: 0.230188\t Accuracy:80.769%\n",
      "Epoch : 2 [26/53 (96%)]\tLoss: 2.262778\t Accuracy:77.778%\n",
      "Epoch : 3 [0/53 (0%)]\tLoss: 0.225578\t Accuracy:100.000%\n",
      "Epoch : 3 [2/53 (4%)]\tLoss: 0.235679\t Accuracy:100.000%\n",
      "Epoch : 3 [4/53 (7%)]\tLoss: 0.808172\t Accuracy:83.333%\n",
      "Epoch : 3 [6/53 (11%)]\tLoss: 0.209748\t Accuracy:87.500%\n",
      "Epoch : 3 [8/53 (15%)]\tLoss: 0.287198\t Accuracy:90.000%\n",
      "Epoch : 3 [10/53 (19%)]\tLoss: 0.351611\t Accuracy:91.667%\n",
      "Epoch : 3 [12/53 (22%)]\tLoss: 0.639203\t Accuracy:85.714%\n",
      "Epoch : 3 [14/53 (26%)]\tLoss: 0.297239\t Accuracy:87.500%\n",
      "Epoch : 3 [16/53 (30%)]\tLoss: 0.720400\t Accuracy:83.333%\n",
      "Epoch : 3 [18/53 (33%)]\tLoss: 0.336298\t Accuracy:85.000%\n",
      "Epoch : 3 [20/53 (37%)]\tLoss: 0.841209\t Accuracy:81.818%\n",
      "Epoch : 3 [22/53 (41%)]\tLoss: 0.724940\t Accuracy:79.167%\n",
      "Epoch : 3 [24/53 (44%)]\tLoss: 0.341880\t Accuracy:80.769%\n",
      "Epoch : 3 [26/53 (48%)]\tLoss: 0.358315\t Accuracy:82.143%\n",
      "Epoch : 3 [28/53 (52%)]\tLoss: 0.728804\t Accuracy:80.000%\n",
      "Epoch : 3 [30/53 (56%)]\tLoss: 0.684453\t Accuracy:78.125%\n",
      "Epoch : 3 [32/53 (59%)]\tLoss: 0.843605\t Accuracy:76.471%\n",
      "Epoch : 3 [34/53 (63%)]\tLoss: 0.323557\t Accuracy:77.778%\n",
      "Epoch : 3 [36/53 (67%)]\tLoss: 0.231576\t Accuracy:78.947%\n",
      "Epoch : 3 [38/53 (70%)]\tLoss: 0.264462\t Accuracy:80.000%\n",
      "Epoch : 3 [40/53 (74%)]\tLoss: 0.203048\t Accuracy:80.952%\n",
      "Epoch : 3 [42/53 (78%)]\tLoss: 0.141836\t Accuracy:81.818%\n",
      "Epoch : 3 [44/53 (81%)]\tLoss: 1.038492\t Accuracy:80.435%\n",
      "Epoch : 3 [46/53 (85%)]\tLoss: 0.221507\t Accuracy:81.250%\n",
      "Epoch : 3 [48/53 (89%)]\tLoss: 1.225808\t Accuracy:80.000%\n",
      "Epoch : 3 [50/53 (93%)]\tLoss: 0.230454\t Accuracy:80.769%\n",
      "Epoch : 3 [26/53 (96%)]\tLoss: 1.604072\t Accuracy:77.778%\n",
      "Epoch : 4 [0/53 (0%)]\tLoss: 0.269647\t Accuracy:100.000%\n",
      "Epoch : 4 [2/53 (4%)]\tLoss: 0.167569\t Accuracy:100.000%\n",
      "Epoch : 4 [4/53 (7%)]\tLoss: 0.857653\t Accuracy:83.333%\n",
      "Epoch : 4 [6/53 (11%)]\tLoss: 0.182650\t Accuracy:87.500%\n",
      "Epoch : 4 [8/53 (15%)]\tLoss: 0.260517\t Accuracy:90.000%\n",
      "Epoch : 4 [10/53 (19%)]\tLoss: 0.366401\t Accuracy:91.667%\n",
      "Epoch : 4 [12/53 (22%)]\tLoss: 0.707187\t Accuracy:85.714%\n",
      "Epoch : 4 [14/53 (26%)]\tLoss: 0.193219\t Accuracy:87.500%\n",
      "Epoch : 4 [16/53 (30%)]\tLoss: 0.668288\t Accuracy:83.333%\n",
      "Epoch : 4 [18/53 (33%)]\tLoss: 0.299322\t Accuracy:85.000%\n",
      "Epoch : 4 [20/53 (37%)]\tLoss: 0.926253\t Accuracy:81.818%\n",
      "Epoch : 4 [22/53 (41%)]\tLoss: 0.649342\t Accuracy:79.167%\n",
      "Epoch : 4 [24/53 (44%)]\tLoss: 0.299580\t Accuracy:80.769%\n",
      "Epoch : 4 [26/53 (48%)]\tLoss: 0.283009\t Accuracy:82.143%\n",
      "Epoch : 4 [28/53 (52%)]\tLoss: 1.094220\t Accuracy:80.000%\n",
      "Epoch : 4 [30/53 (56%)]\tLoss: 0.841680\t Accuracy:78.125%\n",
      "Epoch : 4 [32/53 (59%)]\tLoss: 0.643076\t Accuracy:76.471%\n",
      "Epoch : 4 [34/53 (63%)]\tLoss: 0.372652\t Accuracy:77.778%\n",
      "Epoch : 4 [36/53 (67%)]\tLoss: 0.227736\t Accuracy:78.947%\n",
      "Epoch : 4 [38/53 (70%)]\tLoss: 0.363660\t Accuracy:80.000%\n",
      "Epoch : 4 [40/53 (74%)]\tLoss: 0.389964\t Accuracy:80.952%\n",
      "Epoch : 4 [42/53 (78%)]\tLoss: 0.176927\t Accuracy:81.818%\n",
      "Epoch : 4 [44/53 (81%)]\tLoss: 0.778498\t Accuracy:80.435%\n",
      "Epoch : 4 [46/53 (85%)]\tLoss: 0.168112\t Accuracy:81.250%\n",
      "Epoch : 4 [48/53 (89%)]\tLoss: 0.903589\t Accuracy:80.000%\n",
      "Epoch : 4 [50/53 (93%)]\tLoss: 0.118266\t Accuracy:80.769%\n",
      "Epoch : 4 [26/53 (96%)]\tLoss: 1.683496\t Accuracy:77.778%\n"
     ]
    }
   ],
   "source": [
    "fit(cnn,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.929% \n"
     ]
    }
   ],
   "source": [
    "evaluate(cnn,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
